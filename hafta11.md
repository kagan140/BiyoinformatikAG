# Biyoinformatik Algoritmalara Giri
## Hafta 11

### NP-Hard vs NP-Complete

#### NP-Hard

oklu hizalama probleminde h羹cre hesab覺nda 2^n-1 ilem yap覺lacak.

2 sekans hizalarken 3 h羹cre bilgisine bak覺l覺r. Ka癟 h羹cre i癟in bu tekrarlan覺r? n^2 h羹cre

3 sekans hizalarken 7 h羹cre bilgisine bak覺l覺r. Ka癟 h羹cre i癟in bu tekrarlan覺r? n^3 h羹cre

Hesap zaman覺m覺z O(2^n) olacak. Bu t羹r problemlere **NP-HARD** denir.

#### NP-Complete

Zaten tan覺ml覺 olan NP-Complete problemler var, bu tan覺ml覺lara indirgeyebiliyorsak (d繹n羹t羹rebiliyorsak) problemimize **NP-Complete** t羹r problem denir.
 
### Yapay Zeka'n覺n Temel Prensipleri

#### Makine renmesi (Yapay renme): 

Elimizdeki veriden 繹renme ilemi.

襤statistiksel ara癟lardan faydalanmal覺y覺z.
 
### Randomized QuickSort

c = {6, 3, 2, 8, 4, 5, 1, 7, 0, 9}

- Ad覺m 1: 襤lk 繹nce bir pivot (m) se癟ilir (doal durumda listenin ilk eleman覺 se癟ilir)
  - m = 6
- Ad覺m 2: Pivottan k羹癟羹k ve b羹y羹k olanlar覺 csmall ve clarge olarak ikiye ay覺r覺r.
  - csmall = {3,2,4,5,1,0}, clarge= {8, 7, 9}
- Ad覺m 3: csmall kendi i癟inde, clarge kendi i癟inde 繹zyinelemeli olarak tekrar QuickSort ilemine t璽bi tutulur.
  - ![image](https://user-images.githubusercontent.com/12685802/148225712-9458d962-010d-478a-afa2-3b43024dde9d.png)

Tek eleman kald覺覺 zaman ilem biter.

Peki pivot se癟iminde ilk karakteri almak ne kadar doru? 

Pivotu listenin i癟inden rastgele bir se癟im ile belirlersek en iyi se癟imi yapamayabiliriz ama en k繹t羹 se癟imi yapmaktan korur. Ve bu durum QuickSort'un en iyi durumunu verir.

Sekanslarda motif bulurken de rastgelelikten fayda salayabilir miyiz? 

### Gibbs Sampling ile Motif Bulma

Elimizde sekanslara ait 繹yle bir profil olsa:

![image](https://user-images.githubusercontent.com/12685802/148226931-53de8c24-26c0-4afe-9012-e627e6a94f24.png)

P profiline g繹re AAACCT'nin oluma olas覺l覺覺 nedir:

![image](https://user-images.githubusercontent.com/12685802/148227012-3aab0810-6621-471b-bd9d-380df5d6b71a.png)

Pr(AAACCT | P) = 1/2 * 7/8 * 3/8 * 5/8 * 3/8 * 7/8 = 0.033646 ~= %3.36

Pr(ATACAG | P) = 1/2 * 1/8 * 3/8 * 5/8 * 1/8 * 1/8 = 0.001602 ~= %0.16

Peki elimizde `CTATAAACCTTACATC` gibi bir sekans varsa, P'nin gelme olas覺l覺覺n覺n muhtemel yer (? :D) - P-Most Probable 6-mer deeri nedir? Bunu bulmak i癟in par癟alara b繹leriz: (P profili 6 uzunluundayd覺)

- `CTATAA`
- `TATAAA`
- `ATAAAC`
- `TAAACC`
- `AAACCT`
- `AACCTT`
- `ACCTTA`
- `CCTTAC`
- `CTTACA`
- `TTACAT`
- `TACATC`

Yukar覺daki par癟alar覺n hepsinin hesab覺 yap覺ld覺覺nda 繹yle bir tablo ortaya 癟覺kar:

![image](https://user-images.githubusercontent.com/12685802/148228679-2de6f844-2dfc-4af8-ae14-8764497134b6.png)

En y羹ksek ihtimalli olan `AAACCT`, P-Most Probable 6-mer deeridir.

### P-Most Probable l-mers in Many Sequences - oklu Sekanslarda P-Most Probable l-mer

![image](https://user-images.githubusercontent.com/12685802/148273032-ad55e238-795b-4723-9bcd-0f7c9e6cd90f.png)

Her bir sekans i癟in P-Most Probable 6-mer bulunur.

Ard覺ndan bu sekanslar i癟in bulunan P-Most Probable 6-merler ile yeni bir profil oluturulur:

![image](https://user-images.githubusercontent.com/12685802/148273125-6088672a-683a-4867-aaf0-c07a95c4883d.png)

#### Yeni ve Eski Profilin Kar覺lat覺r覺lmas覺

![image](https://user-images.githubusercontent.com/12685802/148273331-907e5932-3083-491e-adea-8d3be30e9998.png)

K覺rm覺z覺lar frekans覺n artt覺覺n覺, mavi frekans覺n azald覺覺n覺 g繹sterir.

### Gibbs Sampling

Farz edelim ki elimizde 5 (t) sekans覺m覺z var, motif uzunluu (l) da 8

![image](https://user-images.githubusercontent.com/12685802/148274092-8ce8eacf-86db-4e65-9f64-41fe4f0f3732.png)

Bu 5 sekans i癟inden, bilmediimiz motifi arayaca覺z... 

1. Her sekans i癟in rastgele bir balama pozisyonu se癟ilir: `s = (s1, s2, s3, s4, s5)`

![image](https://user-images.githubusercontent.com/12685802/148274430-deb5cc35-fd0b-4a38-ad66-24700cb9aec8.png)

Bu stringler bizim i癟in profile kayna覺 olarak kullan覺lacakt覺r.

2. Rastgele olarak bir sekans (bizim 繹rneimizde 2. sekans, bu sekansa a sekans覺 diyelim) kenara al覺n覺r. 

3. Kalan sekanslar 羹zerinde profil 癟覺kar覺l覺r. Bu profile P diyelim.

![image](https://user-images.githubusercontent.com/12685802/148274831-eb7d9aec-a68a-423f-88d4-9aa360b25561.png)

4. Kenara al覺nan sekans 羹zerinde Pr(a | P) hesab覺 yap覺l覺r.

![image](https://user-images.githubusercontent.com/12685802/148275035-0b9619ed-9c8c-4327-b1c7-41800346ae45.png)

襤lk konum `AAAATTTA` en ansl覺 konum olduundan deer bu kabul edilir.

5. l-mers Pr(a|P) olas覺l覺klar覺n覺n bir da覺l覺m覺n覺 oluturup ve bu da覺l覺ma dayal覺 olarak rastgele yeni bir balang覺癟 pozisyonu se癟ilir. (0.000122 az 繹nceki listede en k羹癟羹k olas覺l覺kt覺)

![image](https://user-images.githubusercontent.com/12685802/148275955-fe745d24-eee0-4f22-92e5-1c3afa7d62d5.png)

Hesaplanan oranlara g繹re balang覺癟 pozisyonlar覺n覺n olas覺l覺klar覺n覺 tan覺mlar覺z. 

![image](https://user-images.githubusercontent.com/12685802/148276300-a08527c8-fe16-449f-8c45-d4cf13798e59.png)

![image](https://user-images.githubusercontent.com/12685802/148276682-ee4b1c4a-c73e-4aa0-b11d-1c44fbe52eb0.png)

6. Entropi oran覺 belli bir seviyeye gelene kadar bu ilemi tekrar yapar覺z.

---

[<< Geri](https://github.com/LIIIs4ma/BiyoinformatikAG/blob/main/hafta10.md)

[>> 襤leri](https://github.com/LIIIs4ma/BiyoinformatikAG/blob/main/hafta12.md)
